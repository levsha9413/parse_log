# parse_log

Работа скрипта состоит из следующих этапов:
1. Определяем аргументы для запуска с помощью библиотеки argparse
2. Создаем объекты re компилируя регулярные выражения для поиска определенных паттернов внутри логов
3. Создаем список файлов логов, исходя из пути указанного в `--path`
4. Так как файл логов может быть очень большим, создаем функции возвращающие объект генератор
   get_string() - генератор для работы с директорией логов или с единичным файлом логов
5. Далее в коде определены несколько функций, выполняющих поиск в строке лога по переданному патерну:
   1. different_elements_counter - возвращает словарь в котором подсчитывает количество разных запросов,
   например {get:15, post:25}
   2. elements_counter - складывает все значения переданного словаря, чтобы получить общее количество элементов
   3. get_top3_elements - получает словарь, сортирует и возвращает новый словарь с тремя элементами с наибольшим значением
   4. get_requests_time - возвращает словарь где ключем являются параметры запроса, а значением время. 
   Содержит дополнительный параметр 'id' для уникальности ключей в словаре.
6. Создаем пустые словари в которых будем агрегировать полученные данные
7. В двух вложенных циклах for: 
   1. перебираем список файлов с логами 
   2. из каждого файла берем по одной строке, вытаскиваем вышеописанными функциями необходимые данные и складываем в объявленные словари
   3. складываем полученные словари в один общий словарь, формируем из него json объект
   4. печатаем json в консоль
   5. записываем json s в отдельный файл
   6. берем следующий файл либо завершаем обработку, если список файлов закончен

Файлы логов для примера лежат в  ./testdir/
Скриншот file.png - скрипт запущен с указанием пути до файла
Скриншот dir.png - скрипт запущен с указанием пути до директории
result2.json - записанный результат работы скрипта